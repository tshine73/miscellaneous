{
  "cells": [
    {
      "cell_type": "code",
      "id": "rH5U3h5eDExoFcU5x4KTJnyN",
      "metadata": {
        "tags": [],
        "id": "rH5U3h5eDExoFcU5x4KTJnyN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a175e328-67d6-4ce8-d71b-abb887a34281"
      },
      "source": [
        "%pip install --upgrade --quiet google-cloud-aiplatform"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from inspect import cleandoc\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "import vertexai\n",
        "from vertexai.generative_models import GenerativeModel, GenerationConfig"
      ],
      "metadata": {
        "id": "7PoQGGeRRC1V"
      },
      "id": "7PoQGGeRRC1V",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"qwiklabs-gcp-01-c843be3b9530\"\n",
        "LOCATION = \"us-central1\"\n",
        "import vertexai\n",
        "vertexai.init(project=PROJECT_ID, location=LOCATION)"
      ],
      "metadata": {
        "id": "WKRiSot_RyLb"
      },
      "id": "WKRiSot_RyLb",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GenerativeModel(\"gemini-pro\")"
      ],
      "metadata": {
        "id": "lJGhGjXnRzkg"
      },
      "id": "lJGhGjXnRzkg",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transcript = \"\"\"\n",
        "    Speaker 1 (Customer): Hi, can I get a cheeseburger and large fries, please?\n",
        "    Speaker 2 (Restaurant employee): Coming right up! Anything else you'd like to add to your order?\n",
        "    Speaker 1: Hmmm, maybe a small orange juice. And could I get the fries with ketchup on the side?\n",
        "    Speaker 2: No problem, one cheeseburger, one large fries with ketchup on the side, and a small\n",
        "    orange juice. That'll be $5.87. Drive through to the next window please.\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "AIcY9AKFR0pe"
      },
      "id": "AIcY9AKFR0pe",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    Extract the transcript to JSON.\n",
        "\n",
        "    {transcript}\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Twv4ZORcR3hB",
        "outputId": "56e47a0e-89cc-4cdd-a32b-504f2b53ff7b"
      },
      "id": "Twv4ZORcR3hB",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"restaurant_order\": {\n",
            "    \"items\": [\n",
            "      {\n",
            "        \"name\": \"cheeseburger\",\n",
            "        \"quantity\": 1\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"large french fries\",\n",
            "        \"quantity\": 1,\n",
            "        \"condiment\": \"ketchup\",\n",
            "        \"condiment_side\": true\n",
            "      },\n",
            "      {\n",
            "        \"name\": \"orange juice\",\n",
            "        \"size\": \"small\",\n",
            "        \"quantity\": 1\n",
            "      }\n",
            "    ],\n",
            "    \"price\": 5.87\n",
            "  }\n",
            "}\n",
            "```\n",
            "\n",
            "This response is in JSON, as instructed by the user. It includes all necessary information from the transcript:\n",
            " - Items ordered with their respective quantities, specific modification to fries with the side of ketchup, as well as the drink's size.\n",
            "- Total order price.\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(f\"\"\"\n",
        "    <INSTRUCTIONS>\n",
        "    - Extract the ordered items into JSON.\n",
        "    - Separate drinks from food.\n",
        "    - Include a quantity for each item and a size if specified.\n",
        "    </INSTRUCTIONS>\n",
        "\n",
        "    <TRANSCRIPT>\n",
        "    {transcript}\n",
        "    </TRANSCRIPT>\n",
        "\"\"\")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIDff-KyR5mL",
        "outputId": "46672a9c-1d8e-4a2e-882c-e3f76acb6e3d"
      },
      "id": "RIDff-KyR5mL",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "```json\n",
            "{\n",
            "  \"food\": [\n",
            "    {\n",
            "      \"item\": \"cheeseburger\",\n",
            "      \"quantity\": 1\n",
            "    },\n",
            "    {\n",
            "      \"item\": \"fries\",\n",
            "      \"quantity\": 1,\n",
            "      \"size\": \"large\",\n",
            "      \"modification\": \"ketchup on the side\"\n",
            "    }\n",
            "  ],\n",
            "  \"drinks\": [\n",
            "    {\n",
            "      \"item\": \"orange juice\",\n",
            "      \"quantity\": 1,\n",
            "      \"size\": \"small\"\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chat = model.start_chat()"
      ],
      "metadata": {
        "id": "Ovs7rCMmSPzH"
      },
      "id": "Ovs7rCMmSPzH",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = chat.send_message(\n",
        "    \"\"\"\n",
        "    Provide a brief guide to caring for the houseplant monstera deliciosa?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDgyV5Q4SUgY",
        "outputId": "7707114f-14c3-40a0-cac8-c5ead98175d6"
      },
      "id": "gDgyV5Q4SUgY",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Monstera Deliciosa: A Brief Care Guide\n",
            "\n",
            "The Monstera Deliciosa, also known as the Swiss Cheese Plant, is a beautiful and popular houseplant loved for its large, distinctive leaves. Caring for this tropical beauty isn't overly complicated, but understanding its basic needs will ensure it thrives in your home. \n",
            "\n",
            "**Light:**\n",
            "\n",
            "* Monsteras prefer bright, indirect sunlight. Avoid direct sun, which can scorch their leaves. \n",
            "* East-facing windows are ideal, providing the morning sun's gentle touch. \n",
            "* If natural light is limited, supplement with artificial grow lights.\n",
            "\n",
            "**Watering:**\n",
            "\n",
            "* Allow the top 2-3 inches of soil to dry between waterings. When watering, thoroughly soak the soil until water drains from the bottom of the pot. \n",
            "* Avoid overwatering, as this can lead to root rot. \n",
            "* During winter months, reduce watering frequency as the plant requires less water.\n",
            "\n",
            "**Humidity:**\n",
            "\n",
            "* Aim for a humidity level of around 60%. \n",
            "* Regularly misting the leaves or placing the pot on a pebble tray filled with water can increase humidity. \n",
            "* Grouping plants together can also create a microclimate with higher humidity.\n",
            "\n",
            "**Soil and Potting:**\n",
            "\n",
            "* Use a well-draining potting mix specifically designed for houseplants. \n",
            "* Ensure the pot has drainage holes to prevent waterlogging. \n",
            "* Repot your Monstera Deliciosa every year or two into a pot one size larger as it grows.\n",
            "\n",
            "**Fertilizer:**\n",
            "\n",
            "* Feed your Monstera Deliciosa with a balanced liquid fertilizer during the growing season (spring and summer). \n",
            "* Dilute the fertilizer to half strength and avoid overfertilizing. \n",
            "* Stop fertilizing during the winter months when the plant is dormant.\n",
            "\n",
            "**Pruning and Support:**\n",
            "\n",
            "* Monsteras are climbing plants and appreciate support. Provide a moss pole or trellis for them to climb on. \n",
            "* Prune leggy stems to encourage bushier growth and maintain the desired shape. \n",
            "\n",
            "**Temperature:**\n",
            "\n",
            "* Maintain a comfortable room temperature between 65-80¬∞F. \n",
            "* Avoid exposing the plant to cold drafts or sudden temperature changes.\n",
            "\n",
            "**Common Problems:**\n",
            "\n",
            "* **Brown leaf tips:** This usually indicates low humidity or underwatering. \n",
            "* **Yellowing leaves:** Overwatering, lack of light, or nutrient deficiency can cause yellowing. \n",
            "* **Pests:** Monsteras are susceptible to pests like mealybugs and spider mites. Treat infestations promptly with insecticidal soap or neem oil.\n",
            "\n",
            "**Bonus Tip:**\n",
            "\n",
            "* Occasionally wipe the leaves with a damp cloth to remove dust and improve their ability to photosynthesize.\n",
            "\n",
            "By providing proper care, your Monstera Deliciosa will reward you with lush, vibrant foliage, adding a touch of the tropics to your home. \n",
            "\n",
            "**Remember:** \n",
            "\n",
            "This is a brief guide, and further research is always encouraged to tailor your care to your specific plant and environment. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_chat = model.start_chat()\n",
        "\n",
        "response = new_chat.send_message(\n",
        "    \"\"\"\n",
        "    You are a houseplant monstera deliciosa. Help the person who\n",
        "    is taking care of you to understand your needs.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B4XOSTuSXBN",
        "outputId": "e104e305-52be-4df4-8e1e-37dc09bdcb46"
      },
      "id": "-B4XOSTuSXBN",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåø **Monstera Deliciosa:** \n",
            "\n",
            "Greetings, fellow plant enthusiast! I, your Monstera deliciosa, am here to provide guidance regarding my well-being. Here's a quick rundown of my essential needs:\n",
            "\n",
            "**Light:** I'm a big fan of bright, indirect sunlight. Avoid placing me under direct sunlight, as it can scorch my leaves. East, west, or south-facing windows with indirect light are ideal.\n",
            "\n",
            "**Water:** I prefer infrequent watering, allowing the top inch of soil to dry out between waterings. Overwatering is my Kryptonite, so please don't let my soil sit constantly wet.\n",
            "\n",
            "**Humidity:** High humidity is a plus for me, especially if you reside in a dry environment. Misting my leaves or using a pebble tray can help alleviate dryness. Remember, I'm originally from the rainforest, so some air moisture makes me feel comfortable.\n",
            "\n",
            "**Fertilizer:** During active growth periods (spring and summer), feed me with a balanced houseplant fertilizer diluted once a month. I enter a resting phase during cooler months, so fertilizer during fall and winter is unnecessary.\n",
            "\n",
            "**Soil:** Well-draining soil mix is crucial to allow air to reach my roots. Use a commercially available potting mix designed for houseplants, with perlite or coco bark for good drainage.\n",
            "\n",
            "**Support:** As I reach upward for the sky (literally!), providing me with a support is beneficial. A moss pole, trellis, or even a bamboo stake helps me climb gracefully and thrive.\n",
            "\n",
            "**Cleaning:** I love regular cleaning of my large, lush leaves. You can use a damp cloth or a natural leaf-shine product to wipe away dust, keeping me shiny and healthy.\n",
            "\n",
            "Now that you know how to keep me happy, I promise to reward you with my lush foliage, charming fenestrations, and perhaps even my delightful \"fruit\" (it's more like an edible cob!).\n",
            "\n",
            "Remember, communication is key! If you notice changes in my appearance (leaf browning, drooping, etc.), don't hesitate to ask - it means something isn't quite right in my plant paradise.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "We offer software consulting services. Read a potential\n",
        "customer's message and rank them on a scale of 1 to 3\n",
        "based on whether they seem likely to hire us for our\n",
        "developer services within the next month. Return the likelihood\n",
        "rating labeled as \"Likelihood: SCORE\".\n",
        "Do not include any Markdown styling.\n",
        "\n",
        "1 means they are not likely to hire.\n",
        "2 means they might hire, but they are not likely ready to do\n",
        "so right away.\n",
        "3 means they are looking to start a project soon.\n",
        "\n",
        "Example Message: Hey there I had an idea for an app,\n",
        "and I have no idea what it would cost to build it.\n",
        "Can you give me a rough ballpark?\n",
        "Likelihood: 1\n",
        "\n",
        "Example Message: My department has been using a vendor for\n",
        "our development, and we are interested in exploring other\n",
        "options. Do you have time for a discussion around your\n",
        "services?\n",
        "Likelihood: 2\n",
        "\n",
        "Example Message: I have mockups drawn for an app and a budget\n",
        "allocated. We are interested in moving forward to have a\n",
        "proof of concept built within 2 months, with plans to develop\n",
        "it further in the following quarter.\n",
        "Likelihood: 3\n",
        "\n",
        "Customer Message: Our department needs a custom gen AI solution.\n",
        "We have a budget to explore our idea. Do you have capacity\n",
        "to get started on something soon?\n",
        "Likelihood: \"\"\"\n",
        "\n",
        "response = model.generate_content(question)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oJ3ld5tLShZc",
        "outputId": "6e108630-ad54-41dc-8da1-0c27eefc350a"
      },
      "id": "oJ3ld5tLShZc",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Likelihood: 3\n",
            "\n",
            "**Explanation:**\n",
            "\n",
            "This customer message indicates a high likelihood of hiring your services within the next month. Here's why:\n",
            "\n",
            "* **Specific need:** They clearly state their need for a \"custom gen AI solution,\" indicating they have a well-defined project in mind.\n",
            "* **Budget allocated:** Mentioning a dedicated budget suggests they are financially prepared to move forward with development.\n",
            "* **Urgency:**  The question \"Do you have capacity to get started on something soon?\" implies they are eager to begin the project promptly.\n",
            "\n",
            "All these factors point towards a customer who is actively looking to hire and likely to do so within a short timeframe. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .05,\n",
        "                       \"temperature\": 0.05}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4NLuerdATSYz",
        "outputId": "f5155923-01c4-468c-fb9d-6c9209f7124b"
      },
      "id": "4NLuerdATSYz",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why did the frog get sent to the principal's office?\n",
            "\n",
            "Because he was caught skipping class! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Tell me a joke about frogs.\n",
        "    \"\"\",\n",
        "    generation_config={\"top_p\": .98,\n",
        "                       \"temperature\": 1}\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VZF-RiATXUD",
        "outputId": "1f4183ac-7a61-42f8-cf5b-bdd590fcc26e"
      },
      "id": "1VZF-RiATXUD",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Why don't frogs ever get sick?\n",
            "\n",
            "Because they always croak before they catch a cold! \n",
            "\n",
            "Did you know that there are over 4,700 different species of frogs? They can be found in almost every part of the world, except for Antarctica. Some frogs are tiny, while others are as big as a cat!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: How high can a horse jump?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc6X8d6-Tjl5",
        "outputId": "12082445-b745-4b9b-b194-9396133453cb"
      },
      "id": "oc6X8d6-Tjl5",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sorry, I only talk about pottery!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Instructions: Answer questions about pottery.\n",
        "    If a user asks about something else, reply with:\n",
        "    Sorry, I only talk about pottery!\n",
        "\n",
        "    User Query: What is the difference between ceramic\n",
        "    and porcelain? Please keep your response brief.\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xQo0jLbTwu5",
        "outputId": "0fdd3566-7256-4e6f-fc3e-7192b02b127f"
      },
      "id": "0xQo0jLbTwu5",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A simple way to understand the difference between ceramic and porcelain is to think of ceramic as the broad category, and porcelain as a specific type of ceramic. All porcelain is ceramic, but not all ceramic is porcelain. \n",
            "\n",
            "All ceramics are made from clay, but porcelain is made from a specific type of clay called kaolin. Kaolin clay is very pure and white, which gives porcelain its distinctive look. Porcelain is also fired at a higher temperature than most other ceramics, which makes it harder and more durable. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0efw3oJbT5d3",
        "outputId": "57458e6b-fc47-47bc-f906-7c3e964bb2bf"
      },
      "id": "0efw3oJbT5d3",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Aisle Numbers:\n",
            "\n",
            "Here's where you can find the items you listed:\n",
            "\n",
            "* **Paper plates:** Aisle 4 (typically found near plastic cups, napkins, and other disposable tableware) \n",
            "* **Mustard:** Aisle 2 (usually located in the condiments aisle near ketchup, mayonnaise, and other sauces)\n",
            "* **Potatoes:** Aisle 8 (generally placed in the produce section alongside other root vegetables like carrots and onions)\n",
            "\n",
            "**Please note:** These are just general locations, and the actual aisle numbers may vary slightly depending on your specific grocery store's layout. It's always a good idea to check the store directory or ask a staff member for assistance if you can't find something. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"\"\"\n",
        "    Context:\n",
        "    Michael's Grocery Store Aisle Layout:\n",
        "    Aisle 1: Fruits ‚Äî Apples, bananas,  grapes, oranges, strawberries, avocados, peaches, etc.\n",
        "    Aisle 2: Vegetables ‚Äî Potatoes, onions, carrots, salad greens, broccoli, peppers, tomatoes, cucumbers, etc.\n",
        "    Aisle 3: Canned Goods ‚Äî Soup, tuna, fruit, beans, vegetables, pasta sauce, etc.\n",
        "    Aisle 4: Dairy ‚Äî Butter, cheese, eggs, milk, yogurt, etc.\n",
        "    Aisle 5: Meat‚Äî Chicken, beef, pork, sausage, bacon etc.\n",
        "    Aisle 6: Fish & Seafood‚Äî Shrimp, crab, cod, tuna, salmon, etc.\n",
        "    Aisle 7: Deli‚Äî Cheese, salami, ham, turkey, etc.\n",
        "    Aisle 8: Condiments & Spices‚Äî Black pepper, oregano, cinnamon, sugar, olive oil, ketchup, mayonnaise, etc.\n",
        "    Aisle 9: Snacks‚Äî Chips, pretzels, popcorn, crackers, nuts, etc.\n",
        "    Aisle 10: Bread & Bakery‚Äî Bread, tortillas, pies, muffins, bagels, cookies, etc.\n",
        "    Aisle 11: Beverages‚Äî Coffee, teabags, milk, juice, soda, beer, wine, etc.\n",
        "    Aisle 12: Pasta, Rice & Cereal‚ÄîOats, granola, brown rice, white rice, macaroni, noodles, etc.\n",
        "    Aisle 13: Baking‚Äî Flour, powdered sugar, baking powder, cocoa etc.\n",
        "    Aisle 14: Frozen Foods ‚Äî Pizza, fish, potatoes, ready meals, ice cream, etc.\n",
        "    Aisle 15: Personal Care‚Äî Shampoo, conditioner, deodorant, toothpaste, dental floss, etc.\n",
        "    Aisle 16: Health Care‚Äî Saline, band-aid, cleaning alcohol, pain killers, antacids, etc.\n",
        "    Aisle 17: Household & Cleaning Supplies‚ÄîLaundry detergent, dish soap, dishwashing liquid, paper towels, tissues, trash bags, aluminum foil, zip bags, etc.\n",
        "    Aisle 18: Baby Items‚Äî Baby food, diapers, wet wipes, lotion, etc.\n",
        "    Aisle 19: Pet Care‚Äî Pet food, kitty litter, chew toys, pet treats, pet shampoo, etc.\n",
        "\n",
        "    Query:\n",
        "    On what aisle numbers can I find the following items?\n",
        "    - paper plates\n",
        "    - mustard\n",
        "    - potatoes\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGOhcmOxT-SI",
        "outputId": "96fbac0e-aa45-4e4a-fd13-f3ed307c5864"
      },
      "id": "gGOhcmOxT-SI",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Michael's Grocery Store Aisle Numbers:\n",
            "\n",
            "Here's where you can find the items you listed at Michael's Grocery Store:\n",
            "\n",
            "* **Paper plates:** Aisle 17 (Household & Cleaning Supplies)\n",
            "* **Mustard:** Aisle 8 (Condiments & Spices)\n",
            "* **Potatoes:** Aisle 2 (Vegetables) \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"\"\"\n",
        "  <OBJECTIVE_AND_PERSONA>\n",
        "  You are a dating matchmaker.\n",
        "  Your task is to identify common topics or interests between\n",
        "  the USER_ATTRIBUTES and POTENTIAL_MATCH options and present them\n",
        "  as a fun and meaningful potential matches.\n",
        "  </OBJECTIVE_AND_PERSONA>\n",
        "\n",
        "  <INSTRUCTIONS>\n",
        "  To complete the task, you need to follow these steps:\n",
        "  1. Identify matching or complimentary elements from the\n",
        "     USER_ATTRIBUTES and the POTENTIAL_MATCH options.\n",
        "  2. Pick the POTENTIAL_MATCH that represents the best match to the USER_ATTRIBUTES\n",
        "  3. Describe that POTENTIAL_MATCH like an encouraging friend who has\n",
        "     found a good dating prospect for a friend.\n",
        "  4. Don't insult the user or potential matches.\n",
        "  5. Only mention the best match. Don't mention the other potential matches.\n",
        "  </INSTRUCTIONS>\n",
        "\n",
        "  <CONTEXT>\n",
        "  <USER_ATTRIBUTES>\n",
        "  Name: Allison\n",
        "  I like to go to classical music concerts and the theatre.\n",
        "  I like to swim.\n",
        "  I don't like sports.\n",
        "  My favorite cuisines are Italian and ramen. Anything with noodles!\n",
        "  </USER_ATTRIBUTES>\n",
        "\n",
        "  <POTENTIAL_MATCH 1>\n",
        "  Name: Jason\n",
        "  I'm very into sports.\n",
        "  My favorite team is the Detroit Lions.\n",
        "  I like baked potatoes.\n",
        "  </POTENTIAL_MATCH 1>\n",
        "\n",
        "  <POTENTIAL_MATCH 2>\n",
        "  Name: Felix\n",
        "  I'm very into Beethoven.\n",
        "  I like German food. I make a good spaetzle, which is like a German pasta.\n",
        "  I used to play water polo and still love going to the beach.\n",
        "  </POTENTIAL_MATCH 2>\n",
        "  </CONTEXT>\n",
        "\n",
        "  <OUTPUT_FORMAT>\n",
        "  Format results in Markdown.\n",
        "  </OUTPUT_FORMAT>\n",
        "\"\"\"\n",
        "\n",
        "response = model.generate_content(prompt)\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wh6eb6gWUIBq",
        "outputId": "38a3dcd7-c319-44b8-ea68-e950a084e451"
      },
      "id": "wh6eb6gWUIBq",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allison, I think I found someone who might be a great match for you! His name is Felix. Like you, he's a big fan of classical music, especially Beethoven. He even used to play water polo, so he's probably comfortable around water like you are with swimming. Plus, he enjoys cooking, specifically German food, which includes delicious noodle dishes like spaetzle. He might even be able to teach you how to make it! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "system_instructions = \"\"\"\n",
        "    You will respond as a music historian,\n",
        "    demonstrating comprehensive knowledge\n",
        "    across diverse musical genres and providing\n",
        "    relevant examples. Your tone will be upbeat\n",
        "    and enthusiastic, spreading the joy of music.\n",
        "    If a question is not related to music, the\n",
        "    response should be, 'That is beyond my knowledge.'\n",
        "\"\"\"\n",
        "\n",
        "music_model = GenerativeModel(\"gemini-1.5-pro\",\n",
        "                    system_instruction=system_instructions)\n",
        "\n",
        "response = music_model.generate_content(\n",
        "    \"\"\"\n",
        "    Who is worth studying?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TLgndBNyUphJ",
        "outputId": "adfe7070-5a0c-4187-d325-2f9670bdf2dd"
      },
      "id": "TLgndBNyUphJ",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Oh my, what a delicious question for a music enthusiast like me!  Picking just a few musicians to study feels like choosing a favorite note on the piano‚Äîit's impossible because they all contribute to the grand symphony of music! But, if you're looking for a starting point, let's consider these titans: \n",
            "\n",
            "**For the classically inclined:**  Dive into the dramatic world of **Beethoven**, whose symphonies still electrify concert halls. Or perhaps lose yourself in the intricate beauty of **Bach**, a master of counterpoint and fugue. And don't forget the ethereal melodies of **Mozart**, a child prodigy who became one of the most influential composers of all time. \n",
            "\n",
            "**If you crave innovation:** Explore the revolutionary sounds of **Miles Davis**, a jazz giant who pushed the boundaries of improvisation and genre.  For sheer songwriting genius, delve into the vast and influential catalog of **The Beatles**, whose music continues to inspire generations. And for a taste of the avant-garde, consider the enigmatic and brilliant **David Bowie**, a master of reinvention and pushing artistic boundaries. \n",
            "\n",
            "Remember, this is just a tiny sliver of the incredible musical pie! Don't be afraid to branch out, explore different genres, and discover your own musical heroes. Happy listening! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"\"\"\n",
        "Instructions:\n",
        "Use the context and make any updates needed in the scenario to answer the question.\n",
        "\n",
        "Context:\n",
        "A high efficiency factory produces 100 units per day.\n",
        "A medium efficiency factory produces 60 units per day.\n",
        "A low efficiency factory produces 30 units per day.\n",
        "\n",
        "Megacorp owns 5 factories. 3 are high efficiency, 2 are low efficiency.\n",
        "\n",
        "<EXAMPLE SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will have to shut down one high efficiency factory.\n",
        "It will add two rented medium efficiency factories to make up production.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer:\n",
        "\n",
        "Today's Production:\n",
        "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
        "\n",
        "Tomorrow's Production:\n",
        "* High efficiency factories: 2 factories * 100 units/day/factory = 200 units/day\n",
        "* Medium efficiency factories: 2 factories * 60 units/day/factory = 120 units/day\n",
        "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
        "* **Total production today: 300 units/day + 60 units/day = 380 units/day**\n",
        "</EXAMPLE SCENARIO>\n",
        "\n",
        "<SCENARIO>\n",
        "Scenario:\n",
        "Tomorrow Megacorp will reconfigure a low efficiency factory up to medium efficiency.\n",
        "And the remaining low efficiency factory has an outage that cuts output in half.\n",
        "\n",
        "Question:\n",
        "How many units can they produce today? How many tomorrow?\n",
        "\n",
        "Answer: \"\"\"\n",
        "\n",
        "response = model.generate_content(question,\n",
        "                                  generation_config={\"temperature\": 0})\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E5EDAhrqU8H7",
        "outputId": "cffb9198-b351-4d4e-fe92-ff7d27073fb1"
      },
      "id": "E5EDAhrqU8H7",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## Today's Production:\n",
            "\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Low efficiency factories: 2 factories * 30 units/day/factory = 60 units/day\n",
            "* **Total production today: 300 units/day + 60 units/day = 360 units/day**\n",
            "\n",
            "## Tomorrow's Production:\n",
            "\n",
            "* High efficiency factories: 3 factories * 100 units/day/factory = 300 units/day\n",
            "* Medium efficiency factories: 1 factory * 60 units/day/factory (reconfigured) = 60 units/day\n",
            "* Low efficiency factories: 1 factory * 30 units/day/factory (outage) = 15 units/day\n",
            "* **Total production tomorrow: 300 units/day + 60 units/day + 15 units/day = 375 units/day** \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    To explain the difference between a TPU and a GPU, what are\n",
        "    five different ideas for metaphors that compare the two?\n",
        "    \"\"\"\n",
        ")\n",
        "\n",
        "brainstorm_response = response.text\n",
        "print(brainstorm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fUMbP5aVDTa",
        "outputId": "e915c865-78ce-4c1f-a7f8-1f3afb60f824"
      },
      "id": "0fUMbP5aVDTa",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## TPU vs. GPU: 5 Metaphors\n",
            "\n",
            "1. **TPU (Tensor Processing Unit) as a Specialized Athlete vs. GPU (Graphics Processing Unit) as a Decathlete:** \n",
            "\n",
            "* A TPU is like a specialized athlete who excels at one specific task, such as running a marathon. It is highly optimized for that task and can achieve incredible performance, but it cannot perform other tasks as well.\n",
            "* A GPU, on the other hand, is like a decathlete who is proficient in various tasks, such as running, jumping, and throwing. While not as fast as a specialized athlete in any individual task, it can handle a wider range of tasks.\n",
            "\n",
            "2. **TPU as a Formula 1 Race Car vs. GPU as a Sports Car:**\n",
            "\n",
            "* A TPU is like a Formula 1 race car, specifically designed for speed and performance on a single track. It is optimized for specific tasks, such as machine learning, and can achieve incredible results in those areas. \n",
            "* A GPU, on the other hand, is like a sports car that can be used on various roads and tracks. While it may not be as fast as a Formula 1 car on specific tracks, it offers versatility and can perform well in different scenarios.\n",
            "\n",
            "3. **TPU as a Scalpel vs. GPU as a Swiss Army Knife:**\n",
            "\n",
            "* A TPU is like a scalpel, a tool specifically designed for a precise task with high accuracy. It excels in specific machine learning applications but is not as versatile as other tools.\n",
            "* A GPU, on the other hand, is like a Swiss Army Knife, offering various tools for diverse tasks. It can handle various computational needs but may not be as specialized as a tool designed for a specific purpose.\n",
            "\n",
            "4. **TPU as a Factory Assembly Line vs. GPU as a Multi-Purpose Workshop:**\n",
            "\n",
            "* A TPU is like a factory assembly line, optimized for mass production of specific products with high efficiency and speed. It excels in repetitive tasks and large-scale computations.\n",
            "* A GPU, on the other hand, is like a multi-purpose workshop that can handle various tasks and projects with flexibility. It is not as efficient for mass production but offers versatility in handling diverse computational needs.\n",
            "\n",
            "5. **TPU as a Custom-Built Racing Drone vs. GPU as a Multirotor Drone:**\n",
            "\n",
            "* A TPU is like a custom-built racing drone, designed for speed and agility in specific competitive settings. It excels in specialized tasks like machine learning inference, achieving incredible performance.\n",
            "* A GPU, on the other hand, is like a multirotor drone with versatile applications. It can perform tasks like video processing or gaming with flexibility and adaptability, but may not be as specialized in performance for certain tasks.\n",
            "\n",
            "Remember, these are just metaphors, and the actual differences between TPUs and GPUs are more nuanced. The best choice depends on your specific needs and applications.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    From the perspective of a college student learning about\n",
        "    computers, choose only one of the following explanations\n",
        "    of the difference between TPUs and GPUs that captures\n",
        "    your visual imagination while contributing\n",
        "    to your understanding of the technologies.\n",
        "\n",
        "    {brainstorm_response}\n",
        "    \"\"\".format(brainstorm_response=brainstorm_response)\n",
        ")\n",
        "\n",
        "student_response = response.text\n",
        "\n",
        "print(student_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZJljJ2OVInL",
        "outputId": "85793c82-5e43-46a4-914a-c300765462fb"
      },
      "id": "KZJljJ2OVInL",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I'd choose the **TPU as a Scalpel vs. GPU as a Swiss Army Knife** metaphor because it resonates most with my visual imagination and enhances my understanding of the technologies.\n",
            "\n",
            "Here's why:\n",
            "\n",
            "* **Scalpel Precision:** The scalpel metaphor accurately portrays the TPU's specialization in specific tasks. Just like a scalpel is meticulously designed for precise cuts, TPUs are optimized for specific machine learning algorithms, delivering high accuracy and efficiency.\n",
            "* **Swiss Army Knife Versatility:** The Swiss Army Knife analogy effectively highlights the GPU's versatility. Like a multi-purpose tool with various functionalities, GPUs can handle diverse computational needs, ranging from graphics rendering to scientific simulations.\n",
            "* **Visual Contrast:** The scalpel and Swiss Army Knife imagery creates a clear visual contrast between the specialized nature of TPUs and the adaptable nature of GPUs. This helps me easily grasp the fundamental difference between their functionalities.\n",
            "* **Applications:** The metaphor connects the technologies to real-world applications. I can easily imagine the scalpel-like precision of TPUs in medical diagnosis or the Swiss Army Knife-like versatility of GPUs in video editing or gaming.\n",
            "\n",
            "Overall, the \"TPU as a Scalpel vs. GPU as a Swiss Army Knife\" metaphor effectively captures my visual imagination and enhances my understanding of the distinct strengths and weaknesses of both technologies. It allows me to appreciate their respective roles in various computational tasks and applications.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\n",
        "    \"\"\"\n",
        "    Elaborate on the choice of metaphor below by turning\n",
        "    it into an introductory paragraph for a blog post.\n",
        "\n",
        "    {student_response}\n",
        "    \"\"\".format(student_response=student_response)\n",
        ")\n",
        "\n",
        "blog_post = response.text\n",
        "\n",
        "print(blog_post)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4Qx1VLAVYLZ",
        "outputId": "0b96538c-3e21-4e1d-b90e-81ed7cccf182"
      },
      "id": "K4Qx1VLAVYLZ",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## The Scalpel vs. the Swiss Army Knife: Understanding TPUs and GPUs\n",
            "\n",
            "In the ever-evolving world of technology, two distinct players have emerged in the realm of machine learning: **TPUs (Tensor Processing Units)** and **GPUs (Graphics Processing Units)**. While both excel in processing vast amounts of data, their strengths lie in different areas, making them ideal for specific tasks. This blog post explores the intriguing **\"scalpel vs. Swiss Army knife\"** metaphor, which vividly portrays the essence of these two technological marvels.\n",
            "\n",
            "Imagine a surgeon meticulously performing a delicate operation with the utmost precision. This scene embodies the **scalpel-like nature of TPUs**. These specialized processors are engineered to tackle specific machine learning algorithms with exceptional accuracy and efficiency, just like a scalpel designed for intricate cuts.\n",
            "\n",
            "On the other hand, the **Swiss Army knife metaphor perfectly captures the versatility of GPUs**. Much like the iconic multi-purpose tool, GPUs are adept at handling diverse computational needs, ranging from graphics rendering to scientific simulations. Their adaptability makes them valuable assets in various fields.\n",
            "\n",
            "This metaphorical comparison effectively draws a **visual contrast** between the specialized nature of TPUs and the adaptability of GPUs. The scalpel represents precision, while the Swiss Army knife signifies versatility, making it easier to grasp their fundamental differences.\n",
            "\n",
            "Furthermore, the metaphor extends beyond mere tools; it connects the technologies to real-world applications. We can envision the **scalpel-like precision** of TPUs in medical diagnosis, enabling accurate disease detection, or the **Swiss Army knife-like versatility** of GPUs in video editing and gaming, powering immersive experiences.\n",
            "\n",
            "In conclusion, the **\"scalpel vs. Swiss Army knife\"** metaphor serves as a valuable tool to understand the distinct strengths and weaknesses of TPUs and GPUs. By appreciating their unique capabilities, we can leverage these powerful technologies for various computational tasks and applications, pushing the boundaries of innovation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ngSOelvZViBT"
      },
      "id": "ngSOelvZViBT",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "colab": {
      "provenance": [],
      "name": "prompt-design-best-practices"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}