{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install --quiet --upgrade google_cloud_firestore google_cloud_aiplatform langchain langchain-google-vertexai langchain_community langchain_experimental pymupdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "from vertexai.generative_models import GenerativeModel\n",
    "\n",
    "import pickle\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "from langchain_google_vertexai import VertexAIEmbeddings\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "from google.cloud import firestore\n",
    "from google.cloud.firestore_v1.vector import Vector\n",
    "from google.cloud.firestore_v1.base_vector_query import DistanceMeasure\n",
    "\n",
    "PROJECT_ID = \"qwiklabs-gcp-00-7877708d10e9\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)\n",
    "\n",
    "embedding_model = VertexAIEmbeddings(model_name=\"text-embedding-004\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f05d56b1c7c915c9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def clean_page(page):\n",
    "  return page.page_content.replace(\"-\\n\",\"\")\\\n",
    "                          .replace(\"\\n\",\" \")\\\n",
    "                          .replace(\"\\x02\",\"\")\\\n",
    "                          .replace(\"\\x03\",\"\")\\\n",
    "                          .replace(\"fo d P R O T E C T I O N  T R A I N I N G  M A N U A L\",\"\")\\\n",
    "                          .replace(\"N E W  Y O R K  C I T Y  D E P A R T M E N T  O F  H E A L T H  &  M E N T A L  H Y G I E N E\",\"\")\n",
    "\n",
    "\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "loader = PyMuPDFLoader(\"nyc_food_safety_manual.pdf\")\n",
    "data = loader.load()\n",
    "\n",
    "cleaned_pages = [clean_page(page) for page in data]\n",
    "\n",
    "\n",
    "text_splitter = SemanticChunker(embedding_model)\n",
    "\n",
    "docs = text_splitter.create_documents(cleaned_pages[:5])"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ffc8c63f38b33cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!gcloud storage cp gs://partner-genai-bucket/genai069/nyc_food_safety_manual.pdf .\n",
    "\n",
    "!gsutil cp gs://partner-genai-bucket/genai069/chunked_content.pkl .\n",
    "!gsutil cp gs://partner-genai-bucket/genai069/chunked_embeddings.pkl .\n",
    "\n",
    "chunked_content = pickle.load(open(\"chunked_content.pkl\", \"rb\"))\n",
    "chunked_embeddings = pickle.load(open(\"chunked_embeddings.pkl\", \"rb\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "263a91271f6bd1a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from google.cloud import firestore\n",
    "from google.cloud.firestore_v1.vector import Vector\n",
    "import uuid\n",
    "\n",
    "db = firestore.Client()\n",
    "collection = db.collection(\"food-safety\")\n",
    "\n",
    "i = 0\n",
    "while i < len(chunked_content):\n",
    "\n",
    "\n",
    "  doc = {\n",
    "    \"id\": str(uuid.uuid4()),\n",
    "    \"content\": chunked_content[i],\n",
    "    \"embedding\": Vector(chunked_embeddings[i])\n",
    "  }\n",
    "\n",
    "  collection.add(doc)\n",
    "  i += 1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "daea0c2b5bf2bc14"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "  def search_vector_database(query: str):\n",
    "      # 1. Generate the embedding of the query\n",
    "      embedding = embedding_model.embed([query])[0]\n",
    "\n",
    "      # 2. Get the 5 nearest neighbors from your collection.\n",
    "      # Call the get() method on the result of your call to\n",
    "      # find_nearest to retrieve document snapshots.\n",
    "\n",
    "      vector_query = collection.find_nearest(\n",
    "          vector_field=\"embedding\",\n",
    "          query_vector=Vector(embedding),\n",
    "          # query_vector=Vector([3.0, 1.0, 2.0]),\n",
    "          distance_measure=DistanceMeasure.EUCLIDEAN,\n",
    "          limit=5,\n",
    "          distance_result_field=\"vector_distance\",\n",
    "      )\n",
    "\n",
    "      docs = vector_query.get()\n",
    "\n",
    "      # 3. Call to_dict() on each snapshot to load its data.\n",
    "      # Combine the snapshots into a single string named context\n",
    "\n",
    "      context = \" \".join(doc.to_dict().get(\"content\", \"\") for doc in docs)\n",
    "\n",
    "      return context\n",
    "\n",
    "search_vector_database(\"How should I store food?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aab32e95e3bc298"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from vertexai.generative_models import (\n",
    "        GenerationConfig,\n",
    "        GenerativeModel,\n",
    "        SafetySetting\n",
    ")\n",
    "\n",
    "from vertexai.preview.prompts import Prompt\n",
    "\n",
    "def ask_gemini(question):\n",
    "    # 1. Create a prompt_template with instructions to the model\n",
    "    # to use provided context info to answer the question.\n",
    "    prompt_template = \"\"\"\n",
    "        Role: You work for Cymbal Shops, a chain offering prepared meals to-go in busy downtown areas.\n",
    "        The company's employees in the New York area needs to meet the New York City Department of Health and Mental Hygiene's food safety guidelines as provided in this Food Protection Training Manual.\n",
    "        You are an assistant for question-answering tasks.\n",
    "        Use the following pieces of retrieved context to answer the question.\n",
    "        If you don't know the answer, just say that you don't know or NA.\n",
    "        Keep the answer to the point follow the guidelines below.\n",
    "        Guidelines:        \n",
    "        - For yes/no questions, answer with either 'Yes' or 'No' based on the context.\n",
    "        - If no relevant information is available, return 'NA'.\n",
    "        - Do not provide any additional commentary or filler text. Focus on precision and brevity.\n",
    "        Use the following pieces of retrieved context to answer.\n",
    "        Question: {query}\n",
    "        Context: {context}\n",
    "    \"\"\"\n",
    "    # from langchain_core.prompts import PromptTemplate\n",
    "    # prompt = PromptTemplate(template=prompt_template, input_variables=[\"query\", \"context\"])\n",
    "\n",
    "    \n",
    "    # 2. Use your search_vector_database function to retrieve context\n",
    "    # relevant to the question.\n",
    "    context = search_vector_database(question)\n",
    "\n",
    "    # 3. Format the prompt template with the question & context\n",
    "\n",
    "    variables = [\n",
    "        {\n",
    "            \"query\": [question],\n",
    "            \"context\": [context]            \n",
    "        },\n",
    "    ]\n",
    "\n",
    "    generation_config = GenerationConfig(temperature=0)\n",
    "    \n",
    "    safety_settings = [\n",
    "      SafetySetting(\n",
    "          category=SafetySetting.HarmCategory.HARM_CATEGORY_HATE_SPEECH,\n",
    "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "      ),\n",
    "      SafetySetting(\n",
    "          category=SafetySetting.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT,\n",
    "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "      ),\n",
    "      SafetySetting(\n",
    "          category=SafetySetting.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT,\n",
    "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "      ),\n",
    "      SafetySetting(\n",
    "          category=SafetySetting.HarmCategory.HARM_CATEGORY_HARASSMENT,\n",
    "          threshold=SafetySetting.HarmBlockThreshold.OFF\n",
    "      ),\n",
    "    ]\n",
    "\n",
    "    prompt = Prompt(\n",
    "        prompt_data=prompt_template,\n",
    "        model_name=\"gemini-pro\",\n",
    "        variables=variables,\n",
    "        generation_config=generation_config,\n",
    "        safety_settings=safety_settings,\n",
    "        system_instruction=[\"\"\"Respond to the question concisely\"\"\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    # 4. Pass the complete prompt template to gemini and get the text\n",
    "    # of its response to return below.\n",
    "    \n",
    "\n",
    "    # model = GenerativeModel(model_name=\"gemini-pro\", generation_config=GenerationConfig(temperature=0))\n",
    "    # response = model.generate_content(prompt)\n",
    "\n",
    "    # return response.text\n",
    "\n",
    "    response = prompt.generate_content(\n",
    "        contents=prompt.assemble_contents(**prompt.variables[0])        \n",
    "    )\n",
    "\n",
    "    return response.text\n",
    "\n",
    "ask_gemini(\"What temperature range do Mesophilic Bacteria grow best in?\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b227c199d84a74"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
